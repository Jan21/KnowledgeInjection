{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 0 1 1 2]\n",
      "Increment first component by value of second component\n",
      "[4 0 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from vector_transformations import VectorTransformations\n",
    "\n",
    "num_values = 5\n",
    "num_components = 5\n",
    "\n",
    "# Initialize with your desired modulo value\n",
    "transformations = VectorTransformations(num_values=num_values)\n",
    "\n",
    "# Create a random vector with num_components components each taking one of num_values possible values\n",
    "vec = np.random.randint(0, num_values, size=num_components)\n",
    "\n",
    "# Apply any transformation\n",
    "\n",
    "# Or get all transformations\n",
    "all_transforms = transformations.get_all_transformations()\n",
    "\n",
    "tr, name = all_transforms[0]\n",
    "print(vec)\n",
    "print(name)\n",
    "print(tr(vec))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rules violated:\n",
      "- First component cannot be even if the second is odd\n",
      "- Third cannot be greater than the fifth\n",
      "- Not all elements can be distinct\n"
     ]
    }
   ],
   "source": [
    "from state_rules import StateRules\n",
    "# Initialize the rules\n",
    "rules = StateRules()\n",
    "\n",
    "# Create a vector to test\n",
    "vec = np.array([2, 3, 6, 4, 5])\n",
    "\n",
    "# Check if it satisfies all rules\n",
    "valid, violations = rules.check_all_rules(vec)\n",
    "\n",
    "# See which rules were violated\n",
    "if not valid:\n",
    "    print(\"Rules violated:\")\n",
    "    for violation in violations:\n",
    "        print(f\"- {violation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total possible vectors: 3125\n",
      "\n",
      "Inalid vectors: 2312 (73.98%)\n"
     ]
    }
   ],
   "source": [
    "# Generate all possible vectors with num_components components, each with num_values possible values\n",
    "# and check which rules they violate\n",
    "\n",
    "# Initialize the rules\n",
    "rules = StateRules()\n",
    "\n",
    "# Total number of possible vectors\n",
    "total_vectors = num_values ** num_components\n",
    "print(f\"Total possible vectors: {total_vectors}\")\n",
    "\n",
    "# Dictionary to track rule violations\n",
    "rule_violation_counts = {}\n",
    "for _, description in rules.get_all_rules():\n",
    "    rule_violation_counts[description] = 0\n",
    "\n",
    "# Counter for valid vectors\n",
    "invalid_vectors_count = 0\n",
    "\n",
    "\n",
    "# Import networkx for graph creation\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from vector_transformations import VectorTransformations\n",
    "\n",
    "# Initialize the transformations\n",
    "transformations = VectorTransformations(num_values)\n",
    "all_transformations = transformations.get_all_transformations()\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Function to generate all possible vectors\n",
    "def generate_all_vectors(num_components, num_values):\n",
    "    total = num_values ** num_components\n",
    "    for i in range(total):\n",
    "        vec = np.zeros(num_components, dtype=int)\n",
    "        temp = i\n",
    "        for j in range(num_components-1, -1, -1):\n",
    "            vec[j] = temp % num_values\n",
    "            temp //= num_values\n",
    "        yield vec\n",
    "\n",
    "# Check each possible vector\n",
    "for vec in generate_all_vectors(num_components, num_values):\n",
    "    valid, violations = rules.check_all_rules(vec)\n",
    "    \n",
    "    if not valid:\n",
    "        invalid_vectors_count += 1\n",
    "    else:\n",
    "        G.add_node(tuple(vec))\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nInalid vectors: {invalid_vectors_count} ({invalid_vectors_count/total_vectors:.2%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add edges for valid transformations\n",
    "for node in G.nodes():\n",
    "    vec = np.array(node)\n",
    "    \n",
    "    # Try each transformation\n",
    "    for idx, (transform_func, description) in enumerate(all_transformations):\n",
    "        # Apply the transformation\n",
    "        transformed_vec = transform_func(vec)\n",
    "        transformed_tuple = tuple(transformed_vec)\n",
    "        \n",
    "        # Check if the transformed vector is a valid node in the graph\n",
    "        if transformed_tuple in G.nodes():\n",
    "            # Add an edge with the transformation index as an attribute\n",
    "            G.add_edge(node, transformed_tuple, transformation=idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the graph: 813\n",
      "Number of edges in the graph: 6349\n",
      "Average number of edges per node: 7.81\n"
     ]
    }
   ],
   "source": [
    "# Count the number of nodes in the graph\n",
    "num_nodes = G.number_of_nodes()\n",
    "print(f\"Number of nodes in the graph: {num_nodes}\")\n",
    "\n",
    "# Count the number of edges in the graph\n",
    "num_edges = G.number_of_edges()\n",
    "print(f\"Number of edges in the graph: {num_edges}\")\n",
    "\n",
    "# Optional: Calculate average number of edges per node\n",
    "avg_edges_per_node = num_edges / G.number_of_nodes() if G.number_of_nodes() > 0 else 0\n",
    "print(f\"Average number of edges per node: {avg_edges_per_node:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "max_path_length = 4\n",
    "num_paths_per_node_train = 200\n",
    "num_paths_per_node_test = 10\n",
    "train_paths = []\n",
    "test_paths = []\n",
    "for node in G.nodes():\n",
    "    # Sample path length from 1 to max_path_length\n",
    "    # We'll use this path length later when generating paths from this node\n",
    "    # This allows us to create training examples with varying path lengths\n",
    "\n",
    "    # Get all outgoing edges from this node\n",
    "    outgoing_edges = G.out_edges(node, data=True)\n",
    "    # Skip if no outgoing edges\n",
    "    if not outgoing_edges:\n",
    "        continue\n",
    "    \n",
    "    # Convert to list for easier sampling\n",
    "    outgoing_edges_list = list(outgoing_edges)\n",
    "    \n",
    "    # Determine number of edges for test set (30%)\n",
    "    num_test_edges = max(1, int(0.3 * len(outgoing_edges_list)))\n",
    "    \n",
    "    # Randomly select edges for test set\n",
    "    test_indices = np.random.choice(\n",
    "        len(outgoing_edges_list), \n",
    "        size=num_test_edges, \n",
    "        replace=False\n",
    "    )\n",
    "    \n",
    "    # Add edges to appropriate sets\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    for idx, edge in enumerate(outgoing_edges_list):\n",
    "        source, target, attrs = edge\n",
    "        if idx in test_indices:\n",
    "            test_data.append((source, target, attrs['transformation']))\n",
    "        else:\n",
    "            train_data.append((source, target, attrs['transformation']))\n",
    "\n",
    "    num_path_per_edge_train = num_paths_per_node_train // len(train_data)\n",
    "    num_path_per_edge_test = num_paths_per_node_test // len(test_data)\n",
    "\n",
    "    # Generate paths for training data\n",
    "    for source, target, transformation in train_data:\n",
    "        # Start each path with the current edge\n",
    "        for _ in range(num_path_per_edge_train):\n",
    "            path = [(source, target, transformation)]\n",
    "            current_node = target\n",
    "            \n",
    "            # Randomly determine path length for this sample (1 to max_path_length)\n",
    "            path_length = np.random.randint(0, max_path_length)\n",
    "            \n",
    "            # Continue the path if needed (path_length > 1)\n",
    "            for step in range(0, path_length):\n",
    "                # Get outgoing edges from current node\n",
    "                next_edges = list(G.out_edges(current_node, data=True))\n",
    "                \n",
    "                # Break if no more outgoing edges\n",
    "                if not next_edges:\n",
    "                    break\n",
    "                \n",
    "                # Randomly select the next edge\n",
    "                next_edge = random.choice(next_edges)\n",
    "                next_source, next_target, next_attrs = next_edge\n",
    "                \n",
    "                # Add to path\n",
    "                path.append((next_source, next_target, next_attrs['transformation']))\n",
    "                \n",
    "                # Update current node\n",
    "                current_node = next_target\n",
    "            \n",
    "            train_paths.append(path)\n",
    "    \n",
    "    # Generate paths for test data\n",
    "    for source, target, transformation in test_data:\n",
    "        # Similar process for test paths\n",
    "        for _ in range(num_path_per_edge_test):\n",
    "            path = [(source, target, transformation)]\n",
    "            current_node = target\n",
    "            \n",
    "            path_length = np.random.randint(1, max_path_length)\n",
    "            \n",
    "            for step in range(0, path_length):\n",
    "                next_edges = list(G.out_edges(current_node, data=True))\n",
    "                if not next_edges:\n",
    "                    break\n",
    "                \n",
    "                next_edge = random.choice(next_edges)\n",
    "                next_source, next_target, next_attrs = next_edge\n",
    "                \n",
    "                path.append((next_source, next_target, next_attrs['transformation']))\n",
    "                current_node = next_target\n",
    "            \n",
    "            test_paths.append(path)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7983"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in test_paths[:10]:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique nodes: 813\n",
      "\n",
      "Example node mappings:\n",
      "Node: (0, 0, 0, 0, 0) -> ID: 0\n",
      "Node: (0, 0, 0, 0, 1) -> ID: 1\n",
      "Node: (0, 0, 0, 0, 2) -> ID: 2\n",
      "Node: (0, 0, 0, 0, 3) -> ID: 3\n",
      "Node: (0, 0, 0, 0, 4) -> ID: 4\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping from node names to IDs\n",
    "node_to_id = {}\n",
    "id_counter = 0\n",
    "\n",
    "# Iterate through all nodes in the graph\n",
    "for node in G.nodes():\n",
    "    if node not in node_to_id:\n",
    "        node_to_id[node] = id_counter\n",
    "        id_counter += 1\n",
    "\n",
    "print(f\"Total number of unique nodes: {len(node_to_id)}\")\n",
    "\n",
    "# Example of the mapping for a few nodes\n",
    "print(\"\\nExample node mappings:\")\n",
    "for i, (node, node_id) in enumerate(list(node_to_id.items())[:5]):\n",
    "    print(f\"Node: {node} -> ID: {node_id}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'E0 . T3 . T18 . T3 . T12', 'output': 'E41'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples = []\n",
    "test_examples = []\n",
    "for path in train_paths:\n",
    "    start = node_to_id[path[0][0]]\n",
    "    end = node_to_id[path[-1][1]]\n",
    "    path_symbols = [f'E{start}']\n",
    "    for edge in path:\n",
    "        path_symbols.append(f'T{edge[2]}')\n",
    "    \n",
    "    input = ' . '.join(path_symbols)\n",
    "    output = f'E{end}'\n",
    "\n",
    "    train_examples.append({'input':input, 'output':output})\n",
    "\n",
    "for path in test_paths:\n",
    "    start = node_to_id[path[0][0]]\n",
    "    end = node_to_id[path[-1][1]]\n",
    "    path_symbols = [f'E{start}']\n",
    "    for edge in path:\n",
    "        path_symbols.append(f'T{edge[2]}')\n",
    "    \n",
    "    input = ' . '.join(path_symbols)\n",
    "    output = f'E{end}'\n",
    "\n",
    "    test_examples.append({'input':input, 'output':output})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 training examples:\n",
      "1. {'input': 'E0 . T3 . T18 . T3 . T12', 'output': 'E41'}\n",
      "2. {'input': 'E0 . T3 . T8 . T3', 'output': 'E11'}\n",
      "3. {'input': 'E0 . T3', 'output': 'E5'}\n",
      "4. {'input': 'E0 . T3 . T18 . T6', 'output': 'E6'}\n",
      "5. {'input': 'E0 . T3', 'output': 'E5'}\n",
      "\n",
      "First 5 test examples:\n",
      "1. {'input': 'E0 . T19 . T3 . T8 . T17', 'output': 'E2'}\n",
      "2. {'input': 'E0 . T19 . T3 . T10', 'output': 'E20'}\n",
      "3. {'input': 'E0 . T19 . T3', 'output': 'E5'}\n",
      "4. {'input': 'E0 . T19 . T19 . T3 . T5', 'output': 'E10'}\n",
      "5. {'input': 'E0 . T19 . T19', 'output': 'E0'}\n"
     ]
    }
   ],
   "source": [
    "# Print first 5 training examples\n",
    "print(\"First 5 training examples:\")\n",
    "for i, example in enumerate(train_examples[:5]):\n",
    "    print(f\"{i+1}. {example}\")\n",
    "\n",
    "# Print first 5 test examples\n",
    "print(\"\\nFirst 5 test examples:\")\n",
    "for i, example in enumerate(test_examples[:5]):\n",
    "    print(f\"{i+1}. {example}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
